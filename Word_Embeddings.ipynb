{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNIUOatM7DCogETQZV7Xcjh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epUnTRn0pYxV","executionInfo":{"status":"ok","timestamp":1666435183651,"user_tz":-120,"elapsed":6294,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"5491d55c-48f0-4e0c-bcd7-ba706ccbac01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n"]}],"source":["!pip3 install torch torchvision tqdm gensim"]},{"cell_type":"code","source":["import torch\n","import numpy \n","import tqdm"],"metadata":{"id":"EO56PUPoql3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcVozvdsqrv0","executionInfo":{"status":"ok","timestamp":1666435188303,"user_tz":-120,"elapsed":9,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"cf621d5e-e0e3-462c-cc52-6f3c1f6720b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f00d1b91570>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["a = torch.ones(5)\n","print(\"Tensor: \")\n","print(a)\n","print(\"Numpy array: \")\n","print(a.numpy(), \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ru6twbFsq4Ie","executionInfo":{"status":"ok","timestamp":1666435188303,"user_tz":-120,"elapsed":7,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"c45ead64-9a89-4e1e-99b2-ec54d5018187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor: \n","tensor([1., 1., 1., 1., 1.])\n","Numpy array: \n","[1. 1. 1. 1. 1.] \n","\n"]}]},{"cell_type":"code","source":["rand = torch.rand(5,3)\n","print(\"Randomly initialized tensor: \", rand, \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ylgeroniq_8s","executionInfo":{"status":"ok","timestamp":1666435190327,"user_tz":-120,"elapsed":253,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"4402bbd5-1039-421a-ac6d-3f48cfc31017"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Randomly initialized tensor:  tensor([[0.7576, 0.2793, 0.4031],\n","        [0.7347, 0.0293, 0.7999],\n","        [0.3971, 0.7544, 0.5695],\n","        [0.4388, 0.6387, 0.5247],\n","        [0.6826, 0.3051, 0.4635]]) \n","\n"]}]},{"cell_type":"code","source":["zeros = torch.zeros(5,3, dtype=torch.long)\n","print(\"Tensor initialized with zeros: \", zeros, \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZKDweSFOrdZp","executionInfo":{"status":"ok","timestamp":1666435190982,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"a97e89fa-d0f2-45bf-afda-602febfb909f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor initialized with zeros:  tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]]) \n","\n"]}]},{"cell_type":"code","source":["zeros = torch.zeros(5,3, dtype=torch.long)\n","print(\"Tensor initialized with zeros: \", zeros, \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNKBOC90rjRj","executionInfo":{"status":"ok","timestamp":1666435195786,"user_tz":-120,"elapsed":261,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"cfaaa49e-3735-4f55-9b7c-f6a1f7a29c81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor initialized with zeros:  tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]]) \n","\n"]}]},{"cell_type":"code","source":["redefined = torch.zeros(5,3, dtype=torch.double)\n","print(\"Tensor initialized with zeros: \", zeros, \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHepRbUVr2dE","executionInfo":{"status":"ok","timestamp":1666435196693,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"b9ce0b89-f5f0-41fe-8c47-b56ee595e82b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor initialized with zeros:  tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]]) \n","\n"]}]},{"cell_type":"code","source":["data = torch.tensor([5.5, 3])\n","print(\"Tensor initilialized with data: \", data, \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzyhaOAzsCZx","executionInfo":{"status":"ok","timestamp":1666435197040,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"55339e02-ec9a-4d29-b769-a5f4c97c3c45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor initilialized with data:  tensor([5.5000, 3.0000]) \n","\n"]}]},{"cell_type":"code","source":["redefined_too = torch.rand_like(redefined, dtype=torch.float)\n","print(\"Initializing randomly based on the size of redefined: \", redefined_too, \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GegzTgZmsFjJ","executionInfo":{"status":"ok","timestamp":1666435200376,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"d3a03d39-1231-4eee-c4d9-68ca5023b9b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing randomly based on the size of redefined:  tensor([[0.4550, 0.5725, 0.4980],\n","        [0.9371, 0.6556, 0.3138],\n","        [0.1980, 0.4162, 0.2843],\n","        [0.3398, 0.5239, 0.7981],\n","        [0.7718, 0.0112, 0.8100]]) \n","\n"]}]},{"cell_type":"code","source":["print(redefined_too.size(), \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcBGvCBgsuk0","executionInfo":{"status":"ok","timestamp":1666435200942,"user_tz":-120,"elapsed":3,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"d9a741bf-512f-4de5-e395-53c050d24cc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 3]) \n","\n"]}]},{"cell_type":"code","source":["x = torch.rand(5, 3)\n","y= torch.rand(5, 3)\n","print(\"Addition: \", x + y, \"\\n\")\n","print(\"Addition alternative syntax: \", torch.add(x, y), \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqWbT9w5uNel","executionInfo":{"status":"ok","timestamp":1666435201250,"user_tz":-120,"elapsed":3,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"22b0ab75-62ba-455f-af47-e2a13861ebd2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Addition:  tensor([[1.3967, 1.2089, 1.4771],\n","        [0.4001, 0.4698, 0.2781],\n","        [1.2007, 1.1880, 1.0924],\n","        [1.2657, 1.8914, 0.7650],\n","        [1.0412, 1.3104, 0.8918]]) \n","\n","Addition alternative syntax:  tensor([[1.3967, 1.2089, 1.4771],\n","        [0.4001, 0.4698, 0.2781],\n","        [1.2007, 1.1880, 1.0924],\n","        [1.2657, 1.8914, 0.7650],\n","        [1.0412, 1.3104, 0.8918]]) \n","\n"]}]},{"cell_type":"code","source":["result = torch.empty(5, 3)\n","print(\"Addition with tensor as argument: \", torch.add(x, y, out=result), \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qe3kJ1aVuWsc","executionInfo":{"status":"ok","timestamp":1666435204186,"user_tz":-120,"elapsed":249,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"3f6fdd45-0531-432d-b12b-df0dca4f3052"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Addition with tensor as argument:  tensor([[1.3967, 1.2089, 1.4771],\n","        [0.4001, 0.4698, 0.2781],\n","        [1.2007, 1.1880, 1.0924],\n","        [1.2657, 1.8914, 0.7650],\n","        [1.0412, 1.3104, 0.8918]]) \n","\n"]}]},{"cell_type":"code","source":["y.add_(x)\n","print(\"Adding x to y: \", y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFq9BVmmuAQT","executionInfo":{"status":"ok","timestamp":1666435204764,"user_tz":-120,"elapsed":217,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"bdff3ce7-0af0-451f-fc98-59ba9a65411b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Adding x to y:  tensor([[1.3967, 1.2089, 1.4771],\n","        [0.4001, 0.4698, 0.2781],\n","        [1.2007, 1.1880, 1.0924],\n","        [1.2657, 1.8914, 0.7650],\n","        [1.0412, 1.3104, 0.8918]])\n"]}]},{"cell_type":"code","source":["print(\"Adding 1: \", y.add_(1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGKwOXEouegm","executionInfo":{"status":"ok","timestamp":1666435207259,"user_tz":-120,"elapsed":4,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"f1c35bc0-e954-48aa-9c07-a785f7ef9382"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Adding 1:  tensor([[2.3967, 2.2089, 2.4771],\n","        [1.4001, 1.4698, 1.2781],\n","        [2.2007, 2.1880, 2.0924],\n","        [2.2657, 2.8914, 1.7650],\n","        [2.0412, 2.3104, 1.8918]])\n"]}]},{"cell_type":"code","source":["print(\"X: \", x, \"\\n\")\n","print(\"Element at index one of each row of the matrix \", x[:, 1], \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiZnP7Ndujfz","executionInfo":{"status":"ok","timestamp":1666435207909,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"0323e405-b750-4def-a023-5624b3654d2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X:  tensor([[0.6397, 0.9743, 0.8300],\n","        [0.0444, 0.0246, 0.2588],\n","        [0.9391, 0.4167, 0.7140],\n","        [0.2676, 0.9906, 0.2885],\n","        [0.8750, 0.5059, 0.2366]]) \n","\n","Element at index one of each row of the matrix  tensor([0.9743, 0.0246, 0.4167, 0.9906, 0.5059]) \n","\n"]}]},{"cell_type":"code","source":["x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)\n","print(\"Resizing: \")\n","print(\"Original\")\n","print(x)\n","print(\"Resized view(16)\", y, \"\\n\")\n","print(\"Resized view(-1, 8)\", z, \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QfQ_pfM2vL2b","executionInfo":{"status":"ok","timestamp":1666435208515,"user_tz":-120,"elapsed":4,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"fea3820c-a662-49aa-c209-090f81ffe2c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Resizing: \n","Original\n","tensor([[ 0.4533,  1.1422,  0.2486, -1.7754],\n","        [-0.0255, -1.0233, -0.5962, -1.0055],\n","        [ 0.4285,  1.4761, -1.7869,  1.6103],\n","        [-0.7040, -0.1853, -0.9962, -0.8313]])\n","Resized view(16) tensor([ 0.4533,  1.1422,  0.2486, -1.7754, -0.0255, -1.0233, -0.5962, -1.0055,\n","         0.4285,  1.4761, -1.7869,  1.6103, -0.7040, -0.1853, -0.9962, -0.8313]) \n","\n","Resized view(-1, 8) tensor([[ 0.4533,  1.1422,  0.2486, -1.7754, -0.0255, -1.0233, -0.5962, -1.0055],\n","        [ 0.4285,  1.4761, -1.7869,  1.6103, -0.7040, -0.1853, -0.9962, -0.8313]]) \n","\n"]}]},{"cell_type":"code","source":["x = torch.ones(2, 2, requires_grad=True)\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4tXudp2wi6G","executionInfo":{"status":"ok","timestamp":1666435211459,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"bc544b65-cdb6-4dea-8085-fb332cc9d92f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n"]}]},{"cell_type":"code","source":["y = x + 2 \n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvsesTIiwmiG","executionInfo":{"status":"ok","timestamp":1666435212228,"user_tz":-120,"elapsed":3,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"01c0b391-1058-4e23-87a9-2336cd225feb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3., 3.],\n","        [3., 3.]], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","source":["print(y.grad_fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hrnr42LmwrBr","executionInfo":{"status":"ok","timestamp":1666435212794,"user_tz":-120,"elapsed":3,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"d25b03ce-72ab-4e67-f683-89d0ce70a8c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<AddBackward0 object at 0x7f00d09ff190>\n"]}]},{"cell_type":"code","source":["z = y * y * 3\n","out = z.mean()\n","\n","print(z, out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1aOJ0xhdwvm8","executionInfo":{"status":"ok","timestamp":1666435214346,"user_tz":-120,"elapsed":4,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"1aa0464c-0472-43ea-b6aa-63c2892744e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[27., 27.],\n","        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"]}]},{"cell_type":"code","source":["out.backward()\n","print(x.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7GBuhNaww7RS","executionInfo":{"status":"ok","timestamp":1666435414126,"user_tz":-120,"elapsed":1015,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"a15f98f3-6715-4a57-b050-4c79fdc27c7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4.5000, 4.5000],\n","        [4.5000, 4.5000]])\n"]}]},{"cell_type":"code","source":["print(x.requires_grad)\n","print((x ** 2).requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZdvBHNZbx1t_","executionInfo":{"status":"ok","timestamp":1666435414126,"user_tz":-120,"elapsed":12,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"4ac5b431-6e8e-46c5-aa89-b59bd942933e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n"]}]},{"cell_type":"code","source":["with torch.no_grad():\n","    print((x ** 2).requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZR71jW1ByCZH","executionInfo":{"status":"ok","timestamp":1666435414126,"user_tz":-120,"elapsed":8,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"5fbeee4d-4d5c-48aa-bf65-21026f65fa8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"metadata":{"id":"OwYnDTFd8gRc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-FBEA-98jaI","executionInfo":{"status":"ok","timestamp":1666435414127,"user_tz":-120,"elapsed":6,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"543f2ec5-2979-480c-d4f7-ee2be809183c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f00d1b91570>"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["word_to_ix = {\"hello\": 0, \"world\": 1}"],"metadata":{"id":"GRgUo_wz8nMP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeds = nn.Embedding(2, 5) \n","lookup_tensor = torch.tensor(list(word_to_ix.values()), dtype=torch.long)"],"metadata":{"id":"hTAS1mrt8rpq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings = embeds(lookup_tensor)\n","print(embeddings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3F2vvZkK8tMc","executionInfo":{"status":"ok","timestamp":1666435544644,"user_tz":-120,"elapsed":238,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"ad57c145-bbf4-49f8-f213-3b5a59ef80b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519],\n","        [-0.1661, -1.5228,  0.3817, -1.0276, -0.5631]],\n","       grad_fn=<EmbeddingBackward0>)\n"]}]},{"cell_type":"code","source":["import string\n","from random import choice\n","def generate_simple_language_corpus(SENTENCE_NUMBER=500, SENTENCE_LENGTH=7):\n","  alpha_d = dict.fromkeys(string.ascii_lowercase, 0)\n","\n","  vocab_dataset = {}\n","  for c, l in enumerate(alpha_d, 0):\n","      vocab_dataset[c] = l*3\n","\n","  prev_word = None\n","  simple_language_text =\"\"\n","\n","  for s in range(SENTENCE_NUMBER):\n","      sentence = []\n","      start_word = choice(range(0, 18))\n","      for w in range(0, SENTENCE_LENGTH):\n","          i = choice([x for x in range(start_word+w+0, start_word+w+3) if x not in [prev_word]])\n","          sentence.append(vocab_dataset[i])\n","          prev_word = i\n","      simple_language_text += \" \".join(sentence) + \"\\n\"\n","\n","  return simple_language_text"],"metadata":{"id":"BW3vOVcw81dO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(generate_simple_language_corpus(SENTENCE_NUMBER=20, SENTENCE_LENGTH=7))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnNp5A0w9pLx","executionInfo":{"status":"ok","timestamp":1666440404920,"user_tz":-120,"elapsed":236,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"43d1b995-b248-4672-9ec0-ffe15476c165"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ooo qqq sss rrr sss ttt www\n","rrr qqq ttt sss uuu vvv www\n","qqq rrr sss ttt vvv uuu www\n","rrr qqq ttt uuu ttt uuu www\n","ggg iii jjj lll mmm nnn mmm\n","ppp rrr sss ttt uuu ttt vvv\n","qqq sss ttt sss vvv uuu xxx\n","ggg iii jjj kkk lll kkk nnn\n","kkk mmm nnn mmm ooo ppp rrr\n","eee ggg iii jjj iii jjj lll\n","ggg iii kkk jjj lll nnn ooo\n","bbb ccc eee fff ggg hhh ggg\n","hhh iii jjj lll kkk lll ooo\n","jjj lll mmm nnn ppp qqq rrr\n","fff ggg hhh iii hhh kkk lll\n","nnn ooo qqq ppp qqq ttt sss\n","nnn ooo ppp qqq sss rrr uuu\n","fff hhh jjj kkk lll kkk lll\n","eee fff hhh jjj iii kkk mmm\n","iii jjj lll kkk nnn mmm ppp\n","\n"]}]},{"cell_type":"code","source":["training_corpus=generate_simple_language_corpus(SENTENCE_NUMBER=500, SENTENCE_LENGTH=7)\n","test_sentence = training_corpus.split()\n","trigrams = [([test_sentence[i-1], test_sentence[i + 1]], test_sentence[i ])\n","              for i in range(1,len(test_sentence) - 1)]\n","print(trigrams[:3])\n","vocab=set(test_sentence)\n","word_to_ix={word: i for i, word in enumerate(vocab)}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5hMaIEPlj3f","executionInfo":{"status":"ok","timestamp":1666449157711,"user_tz":-120,"elapsed":219,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"e59c395c-4d70-43bc-fe19-c59afec40b6b"},"execution_count":129,"outputs":[{"output_type":"stream","name":"stdout","text":["[(['ooo', 'qqq'], 'rrr'), (['rrr', 'rrr'], 'qqq'), (['qqq', 'ttt'], 'rrr')]\n"]}]},{"cell_type":"code","source":["def train_word_embedding_model(training_corpus, EMBEDDING_DIM = 10, EPOCHS = 300, CONTEXT_SIZE = 2):\n","  test_sentence = training_corpus.split()\n","\n","\n","  # we should tokenize the input, but we will ignore that for now\n","  # build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n","  trigrams = [([test_sentence[i-1], test_sentence[i + 1]], test_sentence[i ])\n","              for i in range(1,len(test_sentence) - 1)]\n","  # print the first 3, just so you can see what they look like\n","  print(trigrams[:3])\n","\n","  # deduplicate \n","  vocab = set(test_sentence)\n","\n","  # generate the word index\n","  word_to_ix = {word: i for i, word in enumerate(vocab)}\n","\n","\n","  class NGramLanguageModeler(nn.Module):\n","\n","      def __init__(self, vocab_size, embedding_dim, context_size):\n","          super(NGramLanguageModeler, self).__init__()\n","          self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n","          self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n","          self.linear2 = nn.Linear(128, vocab_size)\n","\n","      def forward(self, inputs):\n","          embeds = self.embeddings(inputs).view((1, -1))\n","          out = F.relu(self.linear1(embeds))\n","          out = self.linear2(out)\n","          log_probs = F.log_softmax(out, dim=1)\n","          return log_probs\n","\n","\n","  losses = []\n","  loss_function = nn.NLLLoss()\n","  model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n","\n","  # Exercise: What do SGD and lr mean? What happenes if you change them?\n","  optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","\n","  for epoch in tqdm.tqdm(range(EPOCHS),total=EPOCHS):\n","      total_loss = 0\n","      for context, target in trigrams:\n","\n","          # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n","          # into integer indices and wrap them in tensors)\n","          context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n","\n","          # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n","          # new instance, you need to zero out the gradients from the old\n","          # instance\n","          model.zero_grad()\n","\n","          # Step 3. Run the forward pass, getting log probabilities over next\n","          # words\n","          log_probs = model(context_idxs)\n","\n","          # Step 4. Compute your loss function. (Again, Torch wants the target\n","          # word wrapped in a tensor)\n","          loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n","\n","          # Step 5. Do the backward pass and update the gradient\n","          loss.backward()\n","          optimizer.step()\n","\n","          # Get the Python number from a 1-element Tensor by calling tensor.item()\n","          total_loss += loss.item()\n","\n","      #print(\"\\t\", total_loss)\n","      losses.append(total_loss)\n","  print(losses) # The loss decreased every iteration over the training data!\n","\n","  return model, word_to_ix, losses"],"metadata":{"id":"EPZ_C2NGUlR3","executionInfo":{"status":"ok","timestamp":1666449161936,"user_tz":-120,"elapsed":707,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}}},"execution_count":130,"outputs":[]},{"cell_type":"code","source":["training_corpus = generate_simple_language_corpus(SENTENCE_NUMBER=500, SENTENCE_LENGTH=7)\n","model, word_to_ix, losses = train_word_embedding_model(training_corpus, EMBEDDING_DIM=5, EPOCHS=10, CONTEXT_SIZE = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wCobRivGwCC","executionInfo":{"status":"ok","timestamp":1666449177445,"user_tz":-120,"elapsed":10936,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"0d821ff6-05fd-43ee-c0e5-7385826e23af"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["[(['qqq', 'ttt'], 'rrr'), (['rrr', 'sss'], 'ttt'), (['ttt', 'vvv'], 'sss')]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:10<00:00,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["[10679.036934614182, 9506.460078239441, 8737.1942730546, 8158.953963577747, 7705.553641736507, 7335.861798495054, 7025.217261195183, 6758.608599573374, 6524.383681803942, 6315.530577838421]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["def get_word_embedding_for_word(word_to_test, word_to_ix):\n","  word_to_test_ix = word_to_ix[word_to_test]\n","  word_to_test_torch = torch.tensor([word_to_test_ix], dtype=torch.long)\n","  \n","  embedding_of_word_to_test = model.embeddings(word_to_test_torch)\n","  return embedding_of_word_to_test\n","\n","def most_similar(word_to_test, word_to_ix):\n","  test_embedding = get_word_embedding_for_word(word_to_test, word_to_ix)\n","\n","  # get embeddings for all other possible words like aaa bbb ccc\n","  cos = torch.nn.CosineSimilarity()\n","  results = {}\n","  for c in string.ascii_lowercase:\n","    c_embedding = get_word_embedding_for_word(c+c+c, word_to_ix)\n","\n","    cosine_similarity = cos(test_embedding, c_embedding)\n","    results[c+c+c] = cosine_similarity.item()\n","  sorted_results =  dict(sorted(results.items(), key=lambda item: -item[1]))\n","  return sorted_results\n","\n","sims = most_similar(\"eee\", word_to_ix)\n","\n","for k,v in sims.items():\n","  print(\"{}: {}\".format(k,v))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s8BGj38qHJMH","executionInfo":{"status":"ok","timestamp":1666449997055,"user_tz":-120,"elapsed":235,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"7086d195-6106-43b5-9fa0-ce5344f04035"},"execution_count":133,"outputs":[{"output_type":"stream","name":"stdout","text":["eee: 1.0000001192092896\n","vvv: 0.6627718806266785\n","iii: 0.4294011890888214\n","ppp: 0.3059576749801636\n","hhh: 0.28882744908332825\n","rrr: 0.27251893281936646\n","bbb: 0.23518235981464386\n","xxx: 0.21666806936264038\n","yyy: 0.18408668041229248\n","fff: 0.1359090805053711\n","ccc: 0.024255692958831787\n","sss: 0.013381972908973694\n","ttt: 0.009966760873794556\n","aaa: -0.05397161841392517\n","ggg: -0.09005162119865417\n","kkk: -0.1759956181049347\n","zzz: -0.25549647212028503\n","nnn: -0.27761080861091614\n","mmm: -0.34966522455215454\n","www: -0.41192978620529175\n","ddd: -0.4676986038684845\n","uuu: -0.5592547655105591\n","lll: -0.6600804924964905\n","jjj: -0.6975461840629578\n","qqq: -0.7777866721153259\n","ooo: -0.8772643208503723\n"]}]},{"cell_type":"code","source":["import gensim \n","from sklearn.decomposition import PCA \n","from matplotlib import pyplot \n","\n","import warnings \n","warnings.filterwarnings('ignore') \n","\n","training_corpus =  generate_simple_language_corpus(SENTENCE_NUMBER=3000, SENTENCE_LENGTH=7)\n","\n","# we have to convert the corpus to a different form for gensim\n","training_corpus_gensim = [w.split(\" \") for w in training_corpus.split(\"\\n\")]\n","\n","\n","model = gensim.models.Word2Vec(training_corpus_gensim, window=2) \n","\n","model.most_similar('ccc')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaSmAE_DKwsp","executionInfo":{"status":"ok","timestamp":1666450137307,"user_tz":-120,"elapsed":1871,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"d26e5ced-e5ac-4f5f-b897-48c1a39d52fa"},"execution_count":134,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"]},{"output_type":"execute_result","data":{"text/plain":["[('ddd', 0.9975908994674683),\n"," ('bbb', 0.9941346645355225),\n"," ('eee', 0.9881815910339355),\n"," ('iii', 0.987351655960083),\n"," ('fff', 0.9868288040161133),\n"," ('aaa', 0.986311674118042),\n"," ('jjj', 0.9852902889251709),\n"," ('ggg', 0.9835245609283447),\n"," ('kkk', 0.9815967082977295),\n"," ('hhh', 0.981393575668335)]"]},"metadata":{},"execution_count":134}]},{"cell_type":"code","source":["!wget https://github.com/dgromann/SemanticComputing/raw/master/tutorial6/word2vec_embeddings.bin\n","!wget https://raw.githubusercontent.com/dgromann/SemComp_WS2018/master/Tutorial6/analogy.txt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6q6aAe7cK9eT","executionInfo":{"status":"ok","timestamp":1666450191995,"user_tz":-120,"elapsed":5096,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"d6bba812-9d96-4e24-c1c1-9a687471026e"},"execution_count":135,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-22 14:50:11--  https://github.com/dgromann/SemanticComputing/raw/master/tutorial6/word2vec_embeddings.bin\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/dgromann/SemanticComputing/master/tutorial6/word2vec_embeddings.bin [following]\n","--2022-10-22 14:50:11--  https://raw.githubusercontent.com/dgromann/SemanticComputing/master/tutorial6/word2vec_embeddings.bin\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 96769269 (92M) [application/octet-stream]\n","Saving to: ‘word2vec_embeddings.bin’\n","\n","word2vec_embeddings 100%[===================>]  92.29M   320MB/s    in 0.3s    \n","\n","2022-10-22 14:50:15 (320 MB/s) - ‘word2vec_embeddings.bin’ saved [96769269/96769269]\n","\n","--2022-10-22 14:50:16--  https://raw.githubusercontent.com/dgromann/SemComp_WS2018/master/Tutorial6/analogy.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 272272 (266K) [text/plain]\n","Saving to: ‘analogy.txt’\n","\n","analogy.txt         100%[===================>] 265.89K  --.-KB/s    in 0.02s   \n","\n","2022-10-22 14:50:16 (12.2 MB/s) - ‘analogy.txt’ saved [272272/272272]\n","\n"]}]},{"cell_type":"code","source":["import gensim\n","from sklearn.decomposition import PCA\n","from matplotlib import pyplot\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"vUVlw2utLEFu","executionInfo":{"status":"ok","timestamp":1666450214436,"user_tz":-120,"elapsed":230,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}}},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["# Let's load the model\n","model = gensim.models.KeyedVectors.load_word2vec_format(\"word2vec_embeddings.bin\", binary=True)\n","\n","# Print the length fo the whole vocabulary \n","print(len(model.wv.vocab))\n","\n","# Print the embedding of a specific word \n","print(model[\"good\"])\n","\n","# Get the 10 most similar words of \"good\"\n","print(model.most_similar(\"good\", topn=10))\n","\n","# Check whether our embeddings are good at the analogy task\n","print(model.most_similar(positive=['women', 'king'], negative=['man'], topn=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7tKNfXALLIi","executionInfo":{"status":"ok","timestamp":1666450243768,"user_tz":-120,"elapsed":1096,"user":{"displayName":"Tarekul islam","userId":"15457657513138755802"}},"outputId":"bdcd3996-8e95-4360-a2a7-0eb388905e73"},"execution_count":137,"outputs":[{"output_type":"stream","name":"stdout","text":["80000\n","[ 0.04052734  0.0625     -0.01745605  0.07861328  0.03271484 -0.01263428\n","  0.00964355  0.12353516 -0.02148438  0.15234375 -0.05834961 -0.10644531\n","  0.02124023  0.13574219 -0.13183594  0.17675781  0.27148438  0.13769531\n"," -0.17382812 -0.14160156 -0.03076172  0.19628906 -0.03295898  0.125\n","  0.25390625  0.12695312 -0.15234375  0.03198242  0.01135254 -0.01361084\n"," -0.12890625  0.01019287  0.23925781 -0.08447266  0.140625    0.13085938\n"," -0.04516602  0.06494141  0.02539062  0.05615234  0.24609375 -0.20507812\n","  0.23632812 -0.00860596 -0.02294922  0.05078125  0.10644531 -0.03564453\n","  0.08740234 -0.05712891  0.08496094  0.23535156 -0.10107422 -0.03564453\n"," -0.04736328  0.04736328 -0.14550781 -0.10986328  0.14746094 -0.23242188\n"," -0.07275391  0.19628906 -0.37890625 -0.07226562  0.04833984  0.11914062\n","  0.06103516 -0.12109375 -0.27929688  0.05200195  0.04907227 -0.02709961\n","  0.1328125   0.03369141 -0.32226562  0.04223633 -0.08789062  0.15429688\n","  0.09472656  0.10351562 -0.02856445  0.00128174 -0.00427246  0.24609375\n"," -0.05957031 -0.16894531 -0.09619141  0.16796875  0.0133667   0.04882812\n","  0.08349609  0.06347656 -0.00872803 -0.08642578 -0.03857422 -0.08251953\n","  0.15722656  0.22753906 -0.00762939 -0.19921875 -0.06347656  0.12792969\n"," -0.06347656 -0.03027344  0.0456543   0.06298828 -0.02526855 -0.06787109\n"," -0.01141357 -0.13574219  0.02978516  0.10400391 -0.15917969 -0.08447266\n","  0.29882812 -0.12597656  0.11425781 -0.08105469 -0.09082031 -0.07910156\n"," -0.11181641 -0.09619141  0.02770996  0.14257812 -0.26757812 -0.09375\n","  0.03979492 -0.17871094 -0.02819824  0.01464844 -0.31640625 -0.24511719\n"," -0.08935547  0.09716797 -0.00964355 -0.14746094  0.15234375  0.21582031\n","  0.05981445  0.23828125 -0.05151367  0.14941406  0.13574219 -0.03222656\n"," -0.265625   -0.11181641 -0.23046875 -0.140625    0.25585938 -0.15429688\n","  0.1796875   0.15527344 -0.21582031  0.36328125 -0.1015625   0.04980469\n","  0.07177734 -0.14550781 -0.03198242  0.00952148 -0.12109375  0.12109375\n","  0.09765625  0.07763672  0.3203125  -0.22265625 -0.08447266 -0.10742188\n","  0.11279297 -0.13867188 -0.21875     0.0145874   0.13378906 -0.00921631\n","  0.00921631  0.16894531  0.16894531 -0.078125   -0.00665283  0.03735352\n"," -0.10888672 -0.25390625  0.01452637 -0.09716797 -0.19628906 -0.01782227\n"," -0.28125    -0.02050781 -0.02905273 -0.09375    -0.17675781  0.21484375\n"," -0.05224609 -0.11572266 -0.01977539 -0.10839844 -0.01342773 -0.15332031\n"," -0.140625   -0.11816406  0.09228516  0.109375    0.05761719 -0.03466797\n","  0.03564453 -0.12011719 -0.14257812 -0.00072479 -0.06689453  0.11914062\n"," -0.10449219  0.07861328 -0.12792969  0.09570312 -0.00817871  0.07128906\n","  0.20703125 -0.03149414  0.09570312  0.17285156 -0.07958984 -0.02429199\n"," -0.07519531 -0.07568359  0.09521484 -0.06494141 -0.00689697 -0.09033203\n","  0.03100586  0.19921875 -0.10644531 -0.11474609  0.18652344 -0.05078125\n","  0.0859375   0.00128937 -0.18847656 -0.20019531 -0.02832031  0.11328125\n","  0.25976562  0.22070312  0.04101562  0.00171661  0.07568359 -0.01196289\n","  0.0177002  -0.05883789 -0.25976562 -0.234375   -0.04956055  0.25976562\n","  0.15332031  0.15136719  0.08300781 -0.15527344  0.04931641  0.07519531\n"," -0.05078125 -0.1328125  -0.13574219  0.04199219 -0.14257812  0.02099609\n","  0.07861328  0.01611328  0.01623535 -0.21582031  0.01599121 -0.04882812\n"," -0.02404785  0.13476562  0.08496094 -0.01196289  0.10009766 -0.13867188\n","  0.08056641 -0.22070312 -0.12011719  0.18945312  0.05444336 -0.05053711\n","  0.00147247  0.14160156 -0.06494141 -0.05566406 -0.09033203 -0.0267334\n"," -0.10498047  0.02416992  0.01422119  0.1875     -0.16503906  0.01538086\n"," -0.04174805  0.05444336 -0.01184082 -0.15625     0.00193024 -0.06982422]\n","[('great', 0.7291510105133057), ('bad', 0.7190051078796387), ('terrific', 0.6889115571975708), ('decent', 0.6837348937988281), ('nice', 0.6836092472076416), ('excellent', 0.644292950630188), ('fantastic', 0.6407778263092041), ('better', 0.6120728254318237), ('solid', 0.5806034803390503), ('lousy', 0.5764201879501343)]\n","[('queen', 0.4827326238155365)]\n"]}]}]}